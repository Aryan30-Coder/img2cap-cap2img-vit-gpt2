{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nkpdL4Il1hx"
   },
   "source": [
    "# ðŸ§  Image Captioning with Bidirectional LSTM\n",
    "\n",
    "Welcome! This notebook walks you through building an image captioning system. The idea is simple but powerful: given an image, the model generates a descriptive caption. We combine a CNN (to extract features from the image) with a Bidirectional LSTM (to generate the text). Letâ€™s dive in!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWraQ5WQ_2ol",
    "outputId": "787e491f-040b-4691-bd95-24fb41483cef"
   },
   "outputs": [],
   "source": [
    "!pip install transformers diffusers gradio torch datasets accelerate torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcAFn8lWmcXi"
   },
   "source": [
    "## ðŸ–¼ï¸ Extracting Features from Images\n",
    "\n",
    "To understand the content of each image, we use a pretrained CNN (like ViT or ResNet) to extract meaningful features. These features form the basis for generating captions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKyRf-I9AQSL"
   },
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c22E-usNDby"
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 688,
     "referenced_widgets": [
      "f3c3086396774ecfbef31bb24308ea2a",
      "c0720b69b4284172b30309094a8549c5",
      "78a6684da63648309d6383884d4e910c",
      "62182f0e8173454fa0c97ceb44449c2f",
      "177450e027fe4cec828c7912b36955bf",
      "345c9449b9434b32acf8a3fb7efd1c78",
      "d56228c056b64591915d6306a85284d8",
      "dd10e819de4c4ea28f8b5e44f381f7a5",
      "f9e30162bb83488ba2b4be1a20be999b",
      "d3a09172622b4514a36e3a11f9314039",
      "49c9c53e258f4da0a00a8f8e2ed81c15",
      "afc71376ad3642b9b70887c939c5b9c7",
      "f677402c644d47a298c65ad02b03533e",
      "81be001d9b4d44979eb2f8a012139aa4",
      "efb38b685f524ad3ab57f5be6a2bc6c9",
      "2e3200a82b30471895b453ecc5ff8050",
      "417a0a174e8547c6b54e046a477ff28e",
      "560e57013ff84bb4b6a28c99dafb0120",
      "e99a51c0fb504efca1204101bdfd1a5b",
      "f3b15f79236c4a9ab27601218cea3812",
      "b0cbf52a12c34effa44fe2def3eab5c3",
      "4b64b00b80ef4d128dad4f147a22b8f7",
      "bfdb8508168b46e89c89b6682c9385db",
      "a343d1ed93fa47a090454a79e079f533",
      "c67a2cccdbe249cfbdc8f358a9b170d0",
      "fa7947ae2fb84b599170ecadafcace63",
      "b4fdc5a6e3f34c22b8432e3d2350b2a0",
      "fd372240c8b44cffbcd27b63fd06ed77",
      "08fd35d9aa22490b86a86c0bb7046074",
      "73daaea62a07436aac8040a860305fc5",
      "4706478ebfe545fba450873c686f6d25",
      "ac3b4d7edbf3464caecdb83802a3ec40",
      "f033a9ab08384c668c8ba6a33eeb7802",
      "2aee56b56df345ffb0b6aea0b48dfc1e",
      "9ba7d10a9fc24c2f942e473d80eb3226",
      "a71c483e78ab4dbebc7e5b60d43339fb",
      "c5b8bfe0c991403f85fa249c67f96b60",
      "0bebda0269e1422f913985407ad58a78",
      "b81c16df2c2e4a2cb6855334d8232712",
      "590253fd570a4e7f8960710808644cac",
      "ff48cc16946d4b97ad39c0d17f3980ac",
      "6d1ec5563ad843b8aa9350662aa26564",
      "85f3bdb24e85479ab8829b4ddacc9816",
      "d22f61ae832a4e62b0c046f7ab486c38",
      "a03dc6370e374acc992b5869754ae392",
      "bf5f1440ef6144d58f26e65d6ab21d49",
      "bffd46933a354ac6bbf1258f32fcd50a",
      "1ce839c397ff43ad93044e1c2c3dfb41",
      "8cd3e33595dd44e3a1bdf5f2dae48b5a",
      "1f6a966e07a8476a90ebb44b1a18bf5c",
      "9d2140f815a74306a67dad2795086204",
      "d6b468548d7b4c5a89354613e6d5efcd",
      "e681eaaf3aa347368ffca4a28ba3ccd9",
      "c644d70b4a054cbb91b70a1b7749e9a9",
      "ff77113ca3764bb1acb12ae2e59f73d3",
      "49a13f30e39a48eaa74ea10c11c4a8af",
      "ae8ff0ab821848a3af88ba710749569f",
      "258aadde12a14e92a3836a8975a41058",
      "0a7be8769e0647029f618b81b7342863",
      "e4be07c4a6e244e486f03ac5227688ef",
      "38bfa04f42db425d972fd4d3e9cbd239",
      "cf5ba2144884496d8bdc281a7026f383",
      "ad7038869c4f4a6da5e1ffaa931761eb",
      "5ff0c369a2e248b1b1801e58f7e0ff94",
      "ddd96364be244bdaa13d6140084abcfa",
      "2efa7c44ee264a9c9c41aeece4c8a9f8",
      "a79dec0bb8e54901b2b0f35ef577d001",
      "8bff37af83bf4ffc8e9cd0e6f2e20366",
      "acd7ab1f2b9e40c7820f1e57f4476f60",
      "a269ddff4c2a46f89d1022f7d492380e",
      "c1ac72c5efa444b9b8f6b1fbe58c5741",
      "e161cd07938448549d8f89daf5534207",
      "8121daf3a5de4896832f22efcd3e1055",
      "d71c4073df574ca9815e187cf5318adb",
      "617740f0097647f6a7f25b526496fdf1",
      "0ed08b049cec4ad3943120089b2105e4",
      "118a7aad08e7496cb9a902057532dedf",
      "cda4a09cea1746e59556ea034c76ff54",
      "31affd7546cc4cd3a2c2d074a2d8fd44",
      "cefb2056c45a48bea2a07c13aca47bb1",
      "266d6325adca419ab40daa44d865373e",
      "9d0b66eab94e430aa1bd610fd2b7035d",
      "1d17121362f24d809dc59ca639491be5",
      "84c6e165ffb948609fb042be465033ac",
      "5165df90ff004fa3bf55ed111475458c",
      "21469faeae31427aa16e964478b08720",
      "a44c8cbacfd34a82be2293e0a9439575",
      "c4b96523a85d4938b6cc2114e7d7547b",
      "2ec33e10e6f0499a9f2715d780e5eaed",
      "974af5419ded457390ffb86be9f0e685",
      "e2ca3b7ed8b24ca4986d023c3eeb2198",
      "c59bde7b6e4e44debbf135f80e2e0142",
      "9fe29204b3c34f329db2220e5491f27e",
      "e3cf6cdb3589425190ebdaa9525aa109",
      "cb6dc63917ea4aaba1a5098244ed7948",
      "5d37b2e7419d4107b1416fa51da618f6",
      "88df33f860854255887a7aa536b097c9",
      "06513d82d6fe42a5a55d9fb87489a333",
      "ab099e056e224eaba846a41bcd2a7f75",
      "ca06e297782c470b95d25f2ad80e4137",
      "de143ed6d790451cbd01dcd6ddda1ca5",
      "9a24984664274dedbaa9429dd76c9862",
      "3a5b57ce4ec343e09bea9888ed1b7e20",
      "faef40a49fb346339a88ccce0a34ee5f",
      "348839b1150c4c3aa6b869d171d32028",
      "ac42cbfbdba94cf18d5b341486002440",
      "21f69f044cae496c88aa7fcd733cfaa9",
      "84e640b3fd7241ebbb5f4bff564519f7",
      "a854de86e3e5485196dee9ebdcfd937a",
      "bcf2ed9318c74848a3fd0da9e177255e",
      "2151a8e44eb8421186b29f29eff72b3c",
      "36d25d0418994017b74307d807117d3a",
      "cc43f82049684f76b8b2d1c3ab86d740",
      "534ec1978c634f538ab1ae96d3bdec9a",
      "ce7bd46bb84f49e4a9834612d74f601f",
      "a45cd57474fc48a9bd64657218390fcd",
      "2df39679ff6e4858a26df42e835e9f0c",
      "98ba14b3dcfb4cb483db80ae249396ec",
      "179e159abb1a443ab04fa15fc562291f",
      "9f86b208df754da494223e04399de325",
      "28834d5a4aeb4fcba477cf9c23ac0142",
      "3a6a2d46941a440b873f876fc875c2e8",
      "9d1e7eb625b64d4b9aa828fce4fb7b6e",
      "84e2894aa525440292c18e8a1f22d759",
      "a85bfda105c140f39a5b871bfb1d75ad",
      "f26cb13f574a4ab6a59b86892c83c225",
      "b3e32ffda9d54a1ea2da7fbdfa1457ed",
      "76d352f5c0fd4f78a46873fc23b566c9",
      "bf91f0345e134e1a9a9f56544348091e",
      "9765bc0444c94e0491f4a5b7405f05c3",
      "1b460bd5f8d64554ac16a9641f516ce6",
      "2b50c8d5582b4dc09973d0956ee0b702",
      "7478bd7d7b5148e7944071bf46f31f04",
      "fc9beea8009b4340b1a6b6f15bf81001",
      "8d14f3f5fedd4e539dc9d9cb9e6436f1",
      "1b76f97b3296477cac60934f71bf8d6a",
      "d0e24c10b46a41bfad44221eab58f6a8",
      "18995c3d97b5450196cc34c4ef0cc5fc",
      "f5c6aefce249483cbd827f99dc9ed2ba",
      "1eab831d9fac4724b3f808d912f69784",
      "c31b0ca059374159a292336f46665b9a",
      "f41a7f90873d40fc97f5252d4341f2be",
      "6363091fd682479bb8d3f8f022397aa3",
      "91606a7054a849d0b7cf58ff80ab4e00",
      "08cd5a9acfcb4eaba36857f43b0deba6",
      "6aceb5c3bcfd4ab5a4ae1a009f66bce6",
      "4b667324a84648c59ea51e0d7a60e1ba",
      "91f0666d85e44c1c946b413683cb8843",
      "4c3bfa6b33824e219216663e0735be32",
      "73ff9e1f882c415fb06ba3ed19e913e1",
      "d9f99caf8b3f41f3bd6e5575dc3cd826",
      "c2995d5bbc324c7b94d1e9a75a8cf8e2",
      "de2fbebdf0d54042b9d861f546bdcbe6",
      "abfc9fe8a5e24d36967acd443a23cbcc",
      "e0c99f5c41e04f059cfd6300dacb3e6b",
      "b927d0440e3d4af09bb4a32e49f147dc",
      "ba7cf2f5310940eb9d7c39cac3fc53fc",
      "d50c046f0a4e486790bfd07f6d2ebb4c",
      "8057c84d06254f11b415116c606613d0",
      "b3fcad82fd92465781f18f3217c1a969",
      "a0536b4be0d446cb84bbe279365d4cf6",
      "989aa42f0f6a4860aadb9829479d4c76",
      "6828bef6239b4961bcbed6d453aa4bdb",
      "37bebb010dc54f999f9ca4f6c878f02e",
      "7605797179634bd691ced1749ea7fa32",
      "f35912946df84f2e997df9ca614e66c5",
      "c880cd498df74cd5a518da8aa61a7841",
      "7eb1b989f136457caf05bd397209d076",
      "7b45646248f34b0bb08a2c02cc2a395a",
      "1dcf7155ee4249a798a76e187b8e2d11",
      "c43638ebb04443f2af106c165fe7cce0",
      "39fe0afb6d184ad5bd73e92893151c91",
      "95b8a78ca32a419fa5c539ba60842a8c",
      "3faef6ef437a490f9f61a1098d21bce1",
      "e225f425ce004eaead5d402cba8a8ca2",
      "30582727cc6e47d5adf6d81abe8ee2c0",
      "25f2008cea074c9d88451f9b6cf021d3",
      "71ddd5b7c136464c9fd4b4808941e2af",
      "d73844dad4434738a09dc729cebf4843",
      "612ff1c79ba841a6a58211d30e2932d2",
      "2c77a168cc5944dd80d27aa3f918889d",
      "a3a6f0b89de0478ba58495b1f1bec18b",
      "63020a30d2664861ae584a3b37538f89",
      "10b5dd0fe0f342c9ac9ec73f0a8e92e0",
      "ccd94ea075b54c32b1472893c3243af6",
      "1d36f7b9b41d4df9b88de5b38924e354",
      "4769c31e102e4cee8b5f8a6f07b7110e"
     ]
    },
    "id": "rntFITeaAQb9",
    "outputId": "a735ccb9-c091-4ce9-eb3e-dc51fb79ffdc"
   },
   "outputs": [],
   "source": [
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "def generate_image_from_caption(caption):\n",
    "    with torch.inference_mode():\n",
    "        image = pipe(caption, num_inference_steps=20, guidance_scale=7.5).images[0]\n",
    "    return image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IV89_DvYmglM"
   },
   "source": [
    "## ðŸ§¹ Cleaning and Tokenizing Captions\n",
    "\n",
    "Before training, we need to clean the text (remove punctuation, lowercase everything, etc.) and tokenize it so that the model can work with numbers instead of raw text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_nUJko9NHdl"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327,
     "referenced_widgets": [
      "d4476ef00b144d87995b627f106aaaed",
      "a5e752381f6b468f8f9b9ded29e5d296",
      "9c854b6127b54ede9144c88e6693a3fc",
      "73e7e7fa27c64622af54fc04f6055a8b",
      "473c7538a3a34095ae1e0ab898b3c5aa",
      "951eefc2eef945138f99b542f1a4cdd1",
      "6586a86118344ef3a381ba4e430d4dfe",
      "35e84a36dc8e47ba9487aa63372f743b",
      "652a79b9932e4504add5335bcdcde55c",
      "ee5366bfbc4e4a55a62ee67d4f91fe2e",
      "1e6d2eb1cc014c9b8a25f6ea1ff481bb",
      "3eecf8b1bb274f7988a8299be918aa40",
      "0342504ac0884f0a825a7cccda85bcf2",
      "e28bb174675a45409e59b3e512e513b9",
      "b90a6089aafd4537a3816c00b00487b7",
      "7dba907080ed42e8a839c928b51d52f0",
      "5ee4bdbfd3dc48a4beda224379da3b74",
      "4844e6cd46f94e448e2d6316af727307",
      "3592463b9142490c8680aff00fb5cad1",
      "6db69538f8164360b88168b74ce822b3",
      "7cd99c1fb2b24e57b8fef1470a1c5499",
      "b3403ca8bed54f4bafe0f6542c16b927",
      "2f2a7017893745beaf20a61a1be76aea",
      "f5fc212479e04a51ba0ff0596ece0125",
      "5f6c0ddfecc2467ea38231053484d386",
      "b50595270ff4475e80104f0617e75919",
      "3d8de4b58a994b5984cdd72ad9cf2012",
      "d3bdf007ace848b8823c8ad4c8717470",
      "53e8b4f7c9124238bd162db54ce156cd",
      "a9a8714aa6ee4566bb3d1d60e74a1d18",
      "3983d3143e5c4c82b48c2b54be19c206",
      "f78ea56adda447d8a4c582d8e7717c0a",
      "f83f5ce88417475589e6833d91b19cf6",
      "67f4f1c5de25499b8f347811d0c1bd72",
      "551d38cc762b46d7a02503bd4347e76c",
      "b6c1e5bfb62c4b919e0f26d6d51b6248",
      "c2c3245c1e1544f9930b5e13df6d08d9",
      "080f1ffee3de4585b733aa77e9727f41",
      "6a34c3e3ad4146839757e6165344c5e5",
      "022d74a65ccb421da22e96c255a050fe",
      "7b55ad1c73bf460cacb7557aa721c52c",
      "860b971092a44cf98edfc85a68fefab4",
      "ae0a1e2b122e4374b157d36dfb681a7b",
      "ca91a2ffc7ad464fb2ad6df766ce8f17",
      "c9288fb4f90448e99bd672e618b39ce6",
      "8dd4fa2e61614bcfa81991e93f4ab515",
      "abb7561678184828aab7974168b82ccb",
      "f2dc44ec65654b98b01fbb59809ba097",
      "05cc0b691b724152b4c4920749fb819d",
      "0f204e2d1c5f40b2ad1a77938d331938",
      "383ab25c87ff482d9399e9a2a2ac3947",
      "7698e1e2f20d4d8badf83f8b05939d2d",
      "48a99053eaee4d25bb524c545cfa1fb5",
      "05257e737b17497aaaa591509d11d55e",
      "b49ac7b4507c4ababd401568dd37646c",
      "afb78ffca2984f65baaacd62407dd074",
      "d61fdbfc5d3f4d4983f42849d5bec220",
      "a55e9ca2214b46cc92907508d832c0e1",
      "f1fa86a77d0144d886828e1a8d0c6a88",
      "4bd77cc7df5141ecbde713103990abcd",
      "9e739788ed344f62aced2bd4b8fa5e95",
      "3a971a3770c04ba789aea22e114c7c0c",
      "89e20e0a1814468e8306354a7f0e2b0f",
      "858e42829e2a4a7aaea6abef24fc2383",
      "bd176e9448714c80ba0b86c0f0f5e5c3",
      "95bbc04a4a8c467fa0c2e5831849ac32",
      "e20658e2b8f3444ba65eef0d84999f5b",
      "3117eebc36c94d6e96446128365d2280",
      "1c474b9d3e754d11813e1961417187c8",
      "0ffef4e18bbf48319fb0005c6be8ea10",
      "af3ef046829b47b59bdc0259f6601ce8",
      "9e5fca84681d4209b9d0ad6708c497e4",
      "238432c2a8564f7e9ba8808d20c5f4b8",
      "650bc1fa0a6345579b3779145ba212fb",
      "07648ee246214a6cb0c5aaaddbdb6e00",
      "bb19294cc00246b18f7bed14cabe20ec",
      "fe9a6e812e584d1c85546cd2eb93e266",
      "ed3833f65f9e4378bc93b564ab28947d",
      "cf15c0a304844967a7f856ad5ac23809",
      "1eb3bb63c50746fa86d3cd99926d5e9c",
      "25be75b218c34f55bab39763134ea32f",
      "bebcc2877556428699acfbf38907db41",
      "9799ba29e2f04c0887558d19c16fc9be",
      "9d9efbeeca894e11aba49adc7c080d6d",
      "28486c0471eb4d60a0014ef9d62217e5",
      "ed15043fc387437fa9e8c47e17623b3f",
      "908eca2231b5427cb7d0480c2f0a4b8b",
      "3641fc5f9884417984c1f25b3f8cf633"
     ]
    },
    "id": "DXFkWbBBwpTg",
    "outputId": "833005e5-ab0f-4ef7-83ea-0f9d78dda8c4"
   },
   "outputs": [],
   "source": [
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-hi\")  # English â†’ Hindi\n",
    "\n",
    "def translate_caption(caption):\n",
    "    return translator(caption, max_length=40)[0]['translation_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9ExQqNqNLUj"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer, pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnROr1rhnRSm"
   },
   "source": [
    "## ðŸ§  Building the Captioning Model\n",
    "\n",
    "We use a Bidirectional LSTM to model the language. This allows the model to learn from both past and future context, leading to more natural and coherent captions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414,
     "referenced_widgets": [
      "99727e53536545688b6f84a379eeee89",
      "8115edb948454795a0d93877b2bdd9a9",
      "6e9c25f9d79e45a1b8f9c75a08217360",
      "72ab52874f114e0b976b335ed4087aa6",
      "d0457a83691c4eb4bb72c4d1f02f1027",
      "23d00d1834464bafb5ab8203c6d4466f",
      "000bbd7be39c4fd4bdce4d0ca820cd46",
      "a2be5bcf43e64c3facb255181b79647c",
      "a25ab429ee5d43e3ac97b6d6368e1bec",
      "81a1fd14e13d466da970e79e06045953",
      "cda610d98e88479b81f81df6e832a6df",
      "9ca05366776d409ab95b4e50a3bc78d1",
      "6ff11c8039794edc9e50b0c636c24d81",
      "862b4d02c7e141a8bb4358e19478bda0",
      "e46c2884599c4fed81a231be5d2ef7a8",
      "d612550a22a54cd4b8a1fd824e63ba0d",
      "7e858483f59749818017d007735f984f",
      "9bda1f335dd34be7abea1259ec4be9cf",
      "7034f052aebb44e8928b74b5881e7299",
      "1004a047e08445d79cc0bb23ce8614e0",
      "c683b0e3a0bc44cc8e22ae27429b8006",
      "111f10912c3643088fc082027b98140f",
      "23aa0e8d940846fe80beaa26d7bde1a6",
      "3f1697089bca483fb2fc76fe957a70f6",
      "b04fb31adaf1449ea02530fba633792d",
      "afaf120b6c3f4571b6c0c2f1d586fca5",
      "557d0226dd79447b81a02be23b042efe",
      "20d112b7f15c41e5baecf6bd95540be3",
      "d8943c602f534071b32924124374bd3d",
      "91779d7d0b83456888664a819b50d777",
      "190a3457994b44368997e9efb4b0b6ed",
      "625e7b0f2303408fb5e8802eaace8e68",
      "68dbfb50913e40dc8d4622073e658794",
      "92dbfd09760746c489a4ed099531e7e9",
      "2f47ea3f48ad47f0bdb8e3fa861891b6",
      "1f6ab28b62a14cd7a2774a09ff0da3a1",
      "346a81acd96749e58d6bd7c153fab54c",
      "03cbbb92540e49fc9a17add5e0a877d9",
      "aaef15e2e07b4e7dac24bf9e3ebec92e",
      "7ddd3fba79e345f797a14302cd4a2857",
      "1c5d2eded65d457099587a65d37506a1",
      "67b51ec872c54424b128a13ea76b03d3",
      "13758ebbac784c34a4bd4cfb6139a032",
      "ecfefaa926d44aa4864508ce1c77e65f",
      "102715bb48da415ab4e17b9ba60f59f4",
      "f2f73b21365c4da3b492495d6c7f2993",
      "47cdf495ba2f4a5ba5c8d1826cbeccab",
      "32179455c57844d297b04c211c8bf8d3",
      "9d00ddc4e2fc4bae89f2c2684a0584ff",
      "c48b242c12964cc2a2dfb778028da06a",
      "2b7d518a17ea4552a41bca488e5da6f8",
      "6f1de11c1a55436dbec9a964c253db95",
      "e6d2dbfa65584c7a936edf5fb4f2aba8",
      "27115fdde53f4ce19f88e43f7a672caf",
      "104a842d7a454fe9a3da20c2a724c469",
      "d7b9d544bd5945d2a565923e0abf583f",
      "a9eef782b9c141d49f021098cd17ae85",
      "b4c9180a85504150bee5b54bb62cde73",
      "264be6a3ec9f472596f62f57bfd81e04",
      "1d54c46e5dc548688111c550eba7fc5a",
      "00af533492db4aca8bf65d11cb089bd6",
      "4c28a69275194822985dd6fbd7b3bb20",
      "765ae4fd29aa4750a04cfcb7378d76ac",
      "7c2ffc74a5054b1bbfc2713d37925711",
      "d01058f39dc24d24965c375bc2706dca",
      "930b42f0963a4b59b1443028dbba0669",
      "5945b0c0c167475ca1500e5f104080cd",
      "53c34306580c4bea9b12a1eafb1e07ed",
      "3abfb3c0d40a472695303360de12dce5",
      "324f26ce6d8d4c9782755407a9fecf60",
      "7ed7eaa7d82d418ca6a992fcc3615673",
      "9a6f04deca5c43f1ba14c44876e154c3",
      "3d2657c98b4848339bd8e128eab25699",
      "46b9cd8b81a74423aff34ee7681d8131",
      "eac72041b32840c892be59dce972a4cf",
      "833da6c383da4c10928aecf51597c881",
      "bb86bd1b2491429682bfffc89316a21a",
      "3a06c35606384813bc9401aaf8316d08",
      "a2f05142f7ea4aca890953ca7153d164",
      "dbb92d867c9b4b8a8c7eb0b9ecebec2b",
      "f0b668c4400443d3985ff368c4cb7041",
      "60853ac73c774f53b8a3e3fc46ae56a7",
      "086270d9fb00425e9b86d7ab9fad6444",
      "33b6f8ba306845cca75bd20ddbfecc2f",
      "9b0cca7be1504e24832c214acca907ba",
      "574deb00f54247bebc32c5976af008e7",
      "c6393db674f540cbbbee4f75e2a78e3a",
      "8cc49dffcbc740159ddbe60dcb7e7a61",
      "26310af9fe7a40e9a4a8f06fb933a049",
      "67cd451d072f4c7eb5d8ef4e823b8306",
      "5080e1ea33264f40ba74f691701433bd",
      "aadb3708057b42e0ad9de6861d18724a",
      "814ce24940184dcd811a5560b1682f40",
      "9b502c7fa749477989dc1bc8dd5c7580",
      "6fe1138799054e088b6501a8cc708d5d",
      "06ed2e379a244718bde0d52a2141d27d",
      "7fc5fc5816d042ecb3e3310b4afe16a9",
      "27cca975bf0f4c7bb5042646944941b1",
      "be548b97ba584be1b713dae4302f667c"
     ]
    },
    "id": "h3crD-aFAQhS",
    "outputId": "fbbfeab6-0b84-4508-ef89-02ebe7e4aa4c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the pre-trained image captioning model and components\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "image_processor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "# Initialize translation pipeline for English -> Hindi\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "max_length = 16\n",
    "num_beams = 1\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
    "\n",
    "def predict_step(image):\n",
    "    try:\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(mode=\"RGB\")\n",
    "\n",
    "        # Pass the image directly as the first argument\n",
    "        pixel_values = image_processor(image, return_tensors=\"pt\").pixel_values\n",
    "        pixel_values = pixel_values.to(device)\n",
    "\n",
    "        print(\"Model before generate:\", model is not None) # Print model status before generate\n",
    "        output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "        preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        caption = preds[0]\n",
    "\n",
    "        hindi_caption = translator(caption, max_length=40)[0]['translation_text']\n",
    "\n",
    "        return caption, hindi_caption\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMLSO2XsnXTN"
   },
   "source": [
    "## ðŸ§ª Generating Captions\n",
    "\n",
    "Letâ€™s test the model on some new images and see how well it generates captions. Also testing out the model on how well it generates images out of the captions we provide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 823,
     "referenced_widgets": [
      "ea1eaf6e72fc475d84a2185292c6e239",
      "ebade6cdab0840c88b2f648006c96776",
      "2efb9dff66694897b7c55618b303f56a",
      "5bb1731dbd3c4fbbbe97b38daec8025f",
      "4e3dd6da5c8d487ba609d359200cf772",
      "6fae759c346d4cf6834db39c40ed7c3d",
      "64354485cace4b01b238c6ab2a457a04",
      "7da5cb98cb3a4f169cf0126c916ed47f",
      "04a2a24137474f99b0967b01a9982fae",
      "bfafa6a3a9764dc090430a51eca303b7",
      "dd77bbdca9e347979c08a984badc2fc1"
     ]
    },
    "id": "Fz05VJqMHkbW",
    "outputId": "0a8e02bb-9778-47ee-8a1c-4bf2548ec662"
   },
   "outputs": [],
   "source": [
    "# Create a Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict_step,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=[\"text\", \"text\"],\n",
    "    title=\"Image Captioning + Generation\",\n",
    "    description=\"Upload an image to get caption and Hindi translation. Or enter a caption to generate an image.\"\n",
    ")\n",
    "\n",
    "iface2 = gr.Interface(\n",
    "    fn=generate_image_from_caption,\n",
    "    inputs=gr.Textbox(label=\"Enter Caption\"),\n",
    "    outputs=gr.Image(type=\"pil\"),\n",
    "    title=\"Text-to-Image Generator\",\n",
    "    description=\"Enter a caption to generate an image using Stable Diffusion.\"\n",
    ")\n",
    "\n",
    "gr.TabbedInterface([iface, iface2], [\"Image â†’ Caption\", \"Caption â†’ Image\"]).launch(debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lNMVxYDnncI"
   },
   "source": [
    "## âœ… Wrapping Up\n",
    "\n",
    "This was a simple but solid implementation of image captioning using a CNN + Bidirectional LSTM. Thereâ€™s a lot of potential to improve this with attention mechanisms or transformers â€” but this gives us a strong starting point.\n",
    "\n",
    "Thanks for checking it out! ðŸš€\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
