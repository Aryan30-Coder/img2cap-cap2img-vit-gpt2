{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \ud83e\udde0 Image Captioning with Bidirectional LSTM\n",
        "\n",
        "Welcome! This notebook walks you through building an image captioning system. The idea is simple but powerful: given an image, the model generates a descriptive caption. We combine a CNN (to extract features from the image) with a Bidirectional LSTM (to generate the text). Let\u2019s dive in!\n"
      ],
      "metadata": {
        "id": "3nkpdL4Il1hx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWraQ5WQ_2ol",
        "outputId": "0afe3539-53b4-482f-cf26-88afd33596ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.33.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.1.0)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.10.2 (from gradio)\n",
            "  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (14.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.13)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.33.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.2-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
            "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, xxhash, uvicorn, tomlkit, semantic-version, ruff, python-multipart, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, groovy, ffmpy, dill, aiofiles, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-24.1.0 datasets-3.6.0 dill-0.3.8 fastapi-0.115.12 ffmpy-0.6.0 gradio-5.33.0 gradio-client-1.10.2 groovy-0.1.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.13 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.3 uvicorn-0.34.3 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers diffusers gradio torch datasets accelerate torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83d\uddbc\ufe0f Extracting Features from Images\n",
        "\n",
        "To understand the content of each image, we use a pretrained CNN (like ViT or ResNet) to extract meaningful features. These features form the basis for generating captions.\n"
      ],
      "metadata": {
        "id": "zcAFn8lWmcXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
        "import torch\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "zKyRf-I9AQSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch"
      ],
      "metadata": {
        "id": "9c22E-usNDby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "def generate_image_from_caption(caption):\n",
        "    with torch.inference_mode():\n",
        "        image = pipe(caption, num_inference_steps=20, guidance_scale=7.5).images[0]\n",
        "    return image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rntFITeaAQb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688,
          "referenced_widgets": [
            "ef45ecfb136a4f4fbf8cf835db3189b6",
            "d07702dcd0ca4dd1872e06b47cecc6c0",
            "f6bd7f58dae74e92844f0a456ef41d43",
            "011c8cd4e7fb43b8b3fd5f7bcfadd116",
            "506ea1ae35a24c14b302624c13a8acf7",
            "df9710a77d734f4bb81bdadb9e5007b5",
            "7e018c365f7c497e9c13af984382820c",
            "1a51bf2008cb4fb197b82b8ff1491bfa",
            "a441712830ae47f9902f50f9e76f428c",
            "20932cfa7b9c479f81ef4334e0fb0c80",
            "6d48b45ae41143eca534394cdd5c7498",
            "23d089cae96c44a689d7e6cdbbf1781f",
            "35a6b921b14a4fa8a63b8cd34d1c2978",
            "6e79785acd844f668a91462da37acef4",
            "a9f4246101124f5c93f781a39f0d682a",
            "c12680d82c6a48628a365607fab8e356",
            "d97c56a160664decab7a92ff54790ebc",
            "07affe9fcdb941e89b75277637852542",
            "9e0742bf83ed4f68841c64277ea988d4",
            "8624ffe2889a48e0a7cf0be75454fe0f",
            "cf199b90368047f2b90f247844d88468",
            "81f1864fb41f45419a866fe3cdd638b9",
            "351c0cde0fbb408ab7659cfd09aed79a",
            "c1a4422c87f74d168217487c08e337b3",
            "567f3a94e0254a07823c69b5e6c6f1d9",
            "9f26cb094f3b4aaea7665e3156eb6b62",
            "2a551ce05f5741138f0e9099b7a08d4c",
            "17e8d6541a854dd8ad3a8d9617185b78",
            "b408de9f6b594e14be37ca3df43df2b5",
            "b7f6e489341646c8822dc3dc425b0591",
            "a3769d07e8764f8c8df3b2f2dc0ae284",
            "e7dec0cac1344e9f8c275ec89839fb2f",
            "a5e743dda2074db18c7d3df4421bc656",
            "35a21a6cf99647229c745be81105c1d7",
            "2bcc06673a3949adb850a9207595bfb9",
            "1119b318e7bf4d11a305e6772528ec18",
            "da7633eddc0141dc909e49b19586d528",
            "ceb9df8d748f48a2b345f243c5584707",
            "a48ecb2ee56f4a639c59a7675e55995d",
            "d1e1790c903948299556edd96bfe8524",
            "3fd7e7be518e46f09176c12e1c96dae3",
            "795767d6c31c47d18e7d7a5031f3d222",
            "de8fb8f992f849429e004f34e0129d77",
            "77e714cb228742cc802f36320f56b8c2",
            "5bdcc59d7e4847d6830a848315e3deab",
            "367907993a2a458099a4b200531befe4",
            "4a675644f4b3460587630e66aa6672b5",
            "cdf3bc242f984f30853574c333302a22",
            "e80ece0a6219492fafb564c41bac0255",
            "68c1c35d412e442288c3c59bf1244b20",
            "a1188b91dc9b442abf529c9a971fc33d",
            "8b7ec0ccba87403fb7d918df48e01d0e",
            "f57fe0effcbc42798a756ec7202ff3fd",
            "1070c1391a5d4ebd9433092e6ce813d0",
            "214801b4bfb44455a4f761ec5ab4d950",
            "b751c0e97f4a416b8689e96f3830ecb2",
            "a4a4fcb83c594c2eafb02a39699ccb78",
            "bffe7710804c4264bb3dd8e39a18cff4",
            "ef8644c6d2e74e4488303e909332f35e",
            "0884aeef5d5846ed8021cbc1e00e77a5",
            "26b9f01140d746e7b28d587107751260",
            "d2d90f160be54f66884bdab1948f1d3a",
            "d05985f4bc184090b0b790139d527362",
            "a07a6c5bc30e492088a722a27dce09b6",
            "e89e25d1d3c54cde8561485d95593cfe",
            "cc497448b7c447d0bec8b0b1d54adbed",
            "3ca4924f42a248e88b64696abdd041ba",
            "64e6213ec24a4db5b630aed3c990401f",
            "58255a59aab846c7a058844f06d08f4b",
            "6353505cf4fb4df8b311e3783dc533ab",
            "ac39c13dff824942a7157f3535fc9dba",
            "adef8ae779e443a59001330026fd35b7",
            "61d2793757f54bdc8e47245492e02023",
            "852492c28e484d2ba4de81eeff8e4f6e",
            "e2de04797ef44b9ea238d57f7a686a46",
            "7bc12c4894ac4dd482e76be25370bdeb",
            "cbb0554007384a02b70872ddf2e0db3d",
            "424a413d9a854eeebe19d9e31782a86e",
            "c9063b1985a24eb4b7696062a1533a14",
            "6214051cfd914929850e0d483a98b6d1",
            "6f88759e97624fa586507558b0f0187a",
            "c91581a0ff2642dabff17160ed5c0b1b",
            "3cf592ecfe9c404a875d47e0d61da50f",
            "f2add5ac74534343b18bc3c0b2b03f8e",
            "896fb277382a422b8a6025d1a319fe02",
            "0971e63bbcdc4a3195fb99cd8352d5b7",
            "83a7f49937b84c3386fe5be03faa3808",
            "5e3a6684718e4e02aba03f6fd0216026",
            "6207732e132a4f81b10481020eed022d",
            "c48b00a801e344488ffb43f833da3191",
            "63b906bbe9a64fd0a3ec2db6f787aecc",
            "2897a8cad8654d6fabf52974ce8b51cc",
            "cf069e3cade342de8f4637f633e21b60",
            "067188d8285a40efb85cf3c6d980fb85",
            "f4fbb19919404270b97771b1b07f3e04",
            "991d150053244865bd0e3062043520d3",
            "41aa1a8e4a2541cfa36caf58316e6abe",
            "762c88a95b2c4928b516b4f961b9f297",
            "52f8d02b5fcb4ea0b8cd0b4f2ed094c1",
            "6f10efab80314e5ba74a01249ecfec0d",
            "4ceb79a9fc17486bbc9dae577ddfe6b5",
            "88d83ed58e35483cbef058b88d1f4129",
            "3edd8752592a4cb3bf6ae204e2250a7b",
            "f2dfa414691a461b971e9294ea26bbe8",
            "cf4c3b7e0aab4cd9b21c25805ad4dd15",
            "ab142801c64840b2aa4cdd3a9ea34cb3",
            "7c99ff94d56840ceadb1e1e1dcaddcff",
            "a23c04f63bb9439a8b14473526f2b0d4",
            "f09ac57a01be4d4ca055bf265b9cf9fb",
            "e063a4905aa34323820dcff2849914f9",
            "8e40c6a7056d4d67b1fab2e90a10ce60",
            "7f734f0869c244b8927a058643171f21",
            "939d814c197b42d3bb6a48b23b084fc7",
            "d56d6e17d2214f46a16cd5cc499bdee5",
            "8113f8c233a4472bb4c98ec305d4eba5",
            "a95dd07dd04848bf81ada772b1f485d3",
            "f605e5bbfae441ec880e49e7b08d39fa",
            "a5013affe12b4890bd2deaa88e41966c",
            "50aaf38e4bab4816be0b11fff41dafe4",
            "f12abd889c384e0f987bf0aa5596050e",
            "d95f181ec9d2424b9bc63073422e1210",
            "acb75e45e7fe4c69ae4902cbd3c84772",
            "235376cce16c462fb275af82850f131a",
            "95b9de76be784345b06101069524988a",
            "26bc693d51cb442aa6a94523a2ea2fbc",
            "10f2e5782aae4b368b61b3562fe22242",
            "772f7333a44e4625a8fe86ebd84a9bfc",
            "09158879037040418383bc4a5ab242c6",
            "8014f25a4b3a4216a82ac14af23dbbf5",
            "cac4ab887c52484880c9cd00ca1869a3",
            "4610e6b1bcf44bee85b60d7792b93a02",
            "616f6754ce864a4db7927e2442306be2",
            "fd3d4b69996e4994a04a70a854bac108",
            "0c5407ae0e0b41fcaf2a7ac6c979d0a8",
            "4ed40814199941e6af057f82d377fd2a",
            "ceb0f0da04ec4102b66429e3e996bb96",
            "ccd451cad56342dbb023212dd479608c",
            "2518a3e779c14410912241e788c6c160",
            "03abfb885b7f4f62999edfb21e584c16",
            "645dd6fcfd184326a90075fc7374992d",
            "6887724ad7934eba83a81a480ee5a1e4",
            "5b8b9fc14f5041e58f1bb0e775556c74",
            "aceee6358e8c47f9b37281908ea2a6c9",
            "1b4b599f225a45e8813fc86542ef7de3",
            "993fdb83938549e6b6ea912a00dfd553",
            "003de51942854fa4b16f608dcd4818da",
            "0f8775b2c5534762b399a34f00805f84",
            "b5c9d8a08bc5417395d61f07a512dfca",
            "28eca6513ef4479abd17bfa04f48b50f",
            "666d1192747745c9b88439168654772f",
            "a17156476c224d1fb9ca5300d7ee1ee3",
            "eaa8526a09044781a14e132fe6383b4f",
            "69b91058a648428ca6c52e7a373ec72f",
            "8d513163aa4e4ebaa2a07de4fb4a5be0",
            "a03b34d3cc4e4243b834b94991fbe5c7",
            "1a42782ed3ef4cf59d14109eb1afc449",
            "e412479d6aae4de9957339a97f0f32f2",
            "d0e3aab0b70543f5a04ce09015b6ee10",
            "31b0f12cec3c4eeebcdf0b2988cd4d6c",
            "cff0e4b18439464d937309f76b8bdaf3",
            "273b169ad4fe44e9a6bc83691c201af2",
            "0ec0bc1424f24dc89ceda6c9ccf2b283",
            "7d56cfbd29d6420dbb446d54b9ea3158",
            "a0dae84e92784e9891b2e9e688018d81",
            "14b1d5ac34424781b35f7a013b3c8645",
            "1a16b9fdadbd45889e8e774a330768a8",
            "23f601557cfa4c63be55b9b3aa2c9419",
            "0913d51520584586b3118f46e84c1b33",
            "623b7fddd8a847df95d471b2629f1086",
            "28b22e2140b44265a5fd58fe649f84cb",
            "d484ce43c9064f98aa6937ddeeeef33d",
            "f868891e720542bbae7858b5eecb314e",
            "a402c24bfbb54afb8e9524129c044885",
            "95bb8880f9824b8a918a29a690c885d6",
            "9d5208a840a44158a3fb557dee2151f5",
            "fa09bc4db2994af8938826a5f916a849",
            "377ca83e65e34579b00724f2b036c0ad",
            "d9d139202cbf4bc7a09d72f468c5302a",
            "20aa979bf9624dc18e43ffb987ed712f",
            "484072b7eea148b6babc25fcc4f9e8f0",
            "cc65f23478f448248e84b52224c305f8",
            "8d93c11800af4efda29552704c5fbca1",
            "18a04153db214997811b73b8fefe87c3",
            "5adf517bd285433ab3d8c9d237aa3889",
            "024fd777286e4a1a85626d28a43b26a8",
            "b79b998ea9494bd894d581ba61640266",
            "7ccb2b2e954043c8bcdc839d98045ca3"
          ]
        },
        "outputId": "62f197bf-a971-4028-8bb4-ac8ea97cfce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef45ecfb136a4f4fbf8cf835db3189b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23d089cae96c44a689d7e6cdbbf1781f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "351c0cde0fbb408ab7659cfd09aed79a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35a21a6cf99647229c745be81105c1d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bdcc59d7e4847d6830a848315e3deab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b751c0e97f4a416b8689e96f3830ecb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ca4924f42a248e88b64696abdd041ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "424a413d9a854eeebe19d9e31782a86e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6207732e132a4f81b10481020eed022d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f10efab80314e5ba74a01249ecfec0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e40c6a7056d4d67b1fab2e90a10ce60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acb75e45e7fe4c69ae4902cbd3c84772"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd3d4b69996e4994a04a70a854bac108"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b4b599f225a45e8813fc86542ef7de3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a03b34d3cc4e4243b834b94991fbe5c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a16b9fdadbd45889e8e774a330768a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "377ca83e65e34579b00724f2b036c0ad"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83e\uddf9 Cleaning and Tokenizing Captions\n",
        "\n",
        "Before training, we need to clean the text (remove punctuation, lowercase everything, etc.) and tokenize it so that the model can work with numbers instead of raw text.\n"
      ],
      "metadata": {
        "id": "IV89_DvYmglM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "B_nUJko9NHdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-hi\")  # English \u2192 Hindi\n",
        "\n",
        "def translate_caption(caption):\n",
        "    return translator(caption, max_length=40)[0]['translation_text']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "11a7a1f9790a416cacdfce8899c2457e",
            "762a4267e4d64f7b9a62976c7c4f3058",
            "a01ee64d9c614ffd912bca72c3f6f702",
            "f6038ccdcde1420d92d208896b91ea30",
            "eab20197f9664fc9bbe6434bccfc9c60",
            "93609c9fa6844eb782b93245a0cd65e8",
            "81f68fe497814b8c8209269ce90ced98",
            "984c120eee6942469ffea4100c4becc0",
            "b08d49ec025248e8bb5a61b8d05b39dc",
            "08b0d6f992874d48a0d8c09061b118f5",
            "553ce1a5851e40379856d4bb8a911e71",
            "eed7154e8d6e43539e775ff40287f8b3",
            "59caff4115f1423488182ba5c89a41f8",
            "df22d84fad2f4866a3c464f0d015d8b8",
            "3519f505eaf34a329b2ee39cb187727c",
            "8dded13a32c64edfa36aa425ddb2bf2c",
            "683b76d8ce8c44189e8d87fce98270f5",
            "61bcfae714fd4a728349fcd42515718b",
            "026ef44c10144066b2031c77ae8ba5e4",
            "1fb5f68de18549f1b2ecba47a8881bbb",
            "2753ecec39654aaa82c74293d20b724e",
            "8ae544f87c4344fba5d8780ef7e4e84f",
            "56b76005f19c46eb85d3d93dd4dd6924",
            "01ac6b9afb5e4faa9964aed79bc3b9f0",
            "f61ec851445344709c5c9afbe74d021b",
            "8a9f1ad6e3c54e5183227438a9016a53",
            "6bb6f19f9e844535912dde0207a3c8e6",
            "73ca90990d914c8eb4c07f0b76f93f22",
            "bac06eda2b974e62acbd680cbefa6a6d",
            "d19dc2d6e9b54edab21a00c382245135",
            "a39c0c9f3d0d44adb52f57b4f00a0fca",
            "369c63cd39e248f39e3126416daa1044",
            "60987953c542422b9c74009947c49360",
            "741ff2b8856446b39580e43c7b391f44",
            "727686fd5cd2446387428ee6bb0e8b16",
            "e0f57b37477d45c6b42d80f31c431f13",
            "09fa838a37f246fe9f8307134e5bd2b7",
            "7a2a34c40204401e882558785d741d28",
            "b6efb7c404d64b60924fce26a34363f3",
            "884c787bcdad498895139d1d0a6d68f3",
            "18106cc1960c454c8fb160e956212386",
            "bbd81c2146b34eeb9b847157ac682dec",
            "9a5c4cba0d844d9cb2834f7830376949",
            "34d16e83f295489f8ac24eaa843df956",
            "e8c36920ee624d1181dde52fe7c1d461",
            "84e3dfecb05b48fbb07e41f53820c69d",
            "f8c00e5993944b3db49cbc9f9098696b",
            "78d1fad6f7a248deb1398e7798d7236f",
            "db5256dc6c8f4278af9f8af8d21f0631",
            "f558c0c7b4904b3dabade66749eed067",
            "5c03bb6297124023a57b147c52ced4b9",
            "c2d8483465f743a4b46b965de11c81ff",
            "9b2cac395581429e8817752190a7b189",
            "67e8af4aa72d404c809f364ee743db1d",
            "0ce3a90bab28401c9f9b92166d348e37",
            "616d08b18b87405da1eabbf730f8d9ec",
            "87096faf0341465c92c4fcf7836bb1bf",
            "ab9d7d1b833443b1ab620d00a9aa8f43",
            "a0cfb5cbadf34bc7b7435ccebaf7eb86",
            "1d7cc007c4cb4e8abee3442205387af6",
            "a61a3e01b26549d092299c32c576d37b",
            "e73841ac94ce4ccba80897c0bb235807",
            "4d3302f54c564fb68a2e31770a9c5d1b",
            "92c6214b6dfe473197c07aa849724c1d",
            "9780f0cd1d5044079b3fb6c124b3e698",
            "c24c289d23ed4890a414944899d021ea",
            "8b96428f59c54627851a63555aaebd11",
            "0005e3cf1dc74fa28baa5e74f088c4ce",
            "7d61bb81d42d41da9f0a781e65c41fc6",
            "6e75867cf9064c3b96467ae971b43d03",
            "2ac4a8327fe24fd480ad40e8821e1b6f",
            "6660dd7b80b04bb5a6cae4fd67f09e11",
            "a6bfe18952854ab7bd50f94a0dbac4f0",
            "0b773599e72647f9b64e303a1cb4ff25",
            "abb36acbe01e4d82bc4453618a07a203",
            "b3b7ad6245bd4084abb3802c3115ea14",
            "6e8b94114782477780f7626ff1ad61df",
            "ad15f34a73604e66bcfe5d0d0b253a23",
            "f896a99e78e245b983b024d69887243a",
            "052cdd29f88d46a0888ed533acb3988f",
            "ed8dabcbd6784a09b2412c4b24140809",
            "b41f0c5464b244d5a60fe87df585785f",
            "b84610576c5c455e8540361f82014132",
            "b8a2fdeb7186442a831ae17ae5fcb010",
            "d21d21ea70d84a00a18e6f52ef6360c5",
            "aed05263dfae4e8c9df1c372c8929933",
            "0698a52f734e4e24a6c33641d16eec51",
            "7172f13ef3c94fa0b71dec1769a5f303"
          ]
        },
        "id": "DXFkWbBBwpTg",
        "outputId": "324e6f0c-08e5-41b7-9abb-b676d4140691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11a7a1f9790a416cacdfce8899c2457e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/306M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eed7154e8d6e43539e775ff40287f8b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/306M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56b76005f19c46eb85d3d93dd4dd6924"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "741ff2b8856446b39580e43c7b391f44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8c36920ee624d1181dde52fe7c1d461"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "616d08b18b87405da1eabbf730f8d9ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b96428f59c54627851a63555aaebd11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad15f34a73604e66bcfe5d0d0b253a23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer, pipeline\n"
      ],
      "metadata": {
        "id": "b9ExQqNqNLUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83e\udde0 Building the Captioning Model\n",
        "\n",
        "We use a Bidirectional LSTM to model the language. This allows the model to learn from both past and future context, leading to more natural and coherent captions.\n"
      ],
      "metadata": {
        "id": "VnROr1rhnRSm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3crD-aFAQhS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b4fd4f4d63b74d90bd9818244717bff7",
            "0fbd212322da43ad98526161137b0f7d",
            "d672c381038f4606882488b9c8254331",
            "e2fc475bb2024619aaf5bacc448504a2",
            "d4fed8865c7448788cb2d8c787f9441f",
            "28f96e37c20e4a5e9ab9524e81dbbdb9",
            "2ad9b9a09c3c45f5a52c9a4c724eba62",
            "0dda91f0bac949f4bc86fc1b8bfe1a95",
            "f5c5e22323dd4684be79774f0ccfa1cf",
            "a71ec5f4424f48c490f8b4d110a5e5b7",
            "5b238abd391841788812b789d3da54bb",
            "15576d1805524c7d994ed3a9754c8b66",
            "9ec24e8df17d410daefaf6ccfb03431c",
            "ad46520ef7dc420d87ad5efe4e12f52d",
            "b644d95e05084c40a0ccbcd5e1faa95d",
            "6f4e6f62d6df46e3b7b87e65cf9406b6",
            "7ec9820c83a347b4ac1193943ee016c1",
            "8a7f3be5f440481d88528ce8d03c3d8e",
            "4d75a6b7b28b4d63aed2b5fd759bfe72",
            "8774118ce71e4f2a8bc2fde17e772251",
            "2e62a8269e0d445e9c93f58fb28d6a7c",
            "ffe22f9a43b34bb7aaafaad64dce6f97",
            "363d0ff406834ad2872f1a3037413283",
            "ab80251835cd4eebbd81b5a53a941b11",
            "2ae9c4533e6e49499910e9e1fd968321",
            "b8f6ef81afc9439fa724ee5aab679726",
            "afe34cc7ec6f4705935bf0d3dbf31d04",
            "12df6694bf534e90a27d03cf4535a801",
            "48c1eac0520245098ab8a92a55cd128e",
            "e6becc3d6f944a08bd687b48ebc67a09",
            "2bc6705e5b334f91b0b7238fe509fa00",
            "6ced55e6ba084c7c90647e07bb5f5423",
            "226e9201210e48678eea2a00ace362fc",
            "b0a58d7603fd45cf8b8617a6b2bf5d27",
            "a21075431bf5436a9f9865cf3e4944f9",
            "0c4bf64e0be149369555154eb83d61b1",
            "076c6fc56988492e91d711e96fa7def3",
            "a30746ad4f6b45f589b55621b2c0582b",
            "4578bb53874746c0ada355dd253bfdef",
            "814781bc9f2a47518899475215fb6d91",
            "209ccf192b4d44048c2402e29b8428c1",
            "0c3057c6dc81409695a2beac167c7558",
            "c494c95ec44c45cea946217d1f5a6689",
            "2435b8d337084bc6b29e9495fdc07859",
            "b102f1d563bc486e99d3cbaff47a9bd9",
            "305527014749408b841b7ca1a5dfecfb",
            "35e89973f8b54cf6a21ebfa25a81da37",
            "b0f21c81d7ec4e29ba0a85b887a2561f",
            "46fdae9870fd48548cf7fb0f4f69bc6e",
            "0b2b890b16af47ce923e3eb493a5175d",
            "0cec807f8bda4f2289200684fda9ac07",
            "afe45578dcf240efbf696111e54ede26",
            "d4d42654b22a47d6b53d5c97deb64a91",
            "981e1a53838746f5b4e7a06814db9d95",
            "5bfa29703a3241db8e5031e0ce791e66",
            "fcdab60d7da144f3b9189a5602c2c01b",
            "bc68121d8b3f451eb16cc33805250adf",
            "9a09760d79274731a8b085a9125b796f",
            "98b4fbf9b4084744994d5349c21a444e",
            "9cc5b9ef2d3b4f8aa54a073d7860325d",
            "066a1e530eec4b9c866269399ecd4481",
            "c5ac23aa85af4d79baf098a129953695",
            "3124516cdae64a10a399a26b7b89cb9e",
            "03381064317e495db5a8fe91f97ee68a",
            "813f800659264dbe9a00e1092e273181",
            "47d2c231c8c34bb9b8d6d7bf32f708e0",
            "975cd5472573418685a1fec5e91506c2",
            "b10886e89a614592833ef35df5ad20bb",
            "63d4aed1d82647a59610ed4abff673da",
            "205a64b040ee4510b947612470a1a93a",
            "a0eb9372531f45d0abb2fa70f5f71d0f",
            "240fb1e1677f4ca7b5d9eb9d6b57f312",
            "97f413949f9f47528a76ca9a35af7117",
            "3a3341b420c0431f98427ee64bb04c9e",
            "fe3ffd85556e4b8e9f730bad8249ea69",
            "535c75bc609a49fb903d5fac42589c31",
            "7b240d3615f145ab8b76ecba23fe4896",
            "dae6f9f7cc4442bdb96f9e9c95ce4f67",
            "b06ac0dba9b74a4ca514f64a50c00b0d",
            "18cd05844ccd4bc891b05c54ad07c9d3",
            "85b08aa865b04f1e869fce0589bd4db9",
            "20574d795e0543a4b092054deab1ed9f",
            "5a3754dee2894f508e2b531793e9d3ca",
            "4f8559c35efb4b77b388172790068318",
            "283035c3d0024adabdd1fe0a5d72bbe2",
            "5792182505fa47829b2c6870516919c1",
            "30d20f3048da44a6b155a27b4d6d3d86",
            "5d0f13ad5df6448ba82ed58f429e3563",
            "92f14646a51d4a1ca977f98a0db511e7",
            "de96b42a44b74b5c895a27b93504f885",
            "3362d0ad8fd042558627605e3ca2979c",
            "b3f6f37fe5c344b9a567678257a4ce8e",
            "23c18935a0c04b638a72d7cd490e8e96",
            "cc4837b05bbb4e8ba8178d6736ae5711",
            "0e86aebc2af6471d9c647f3abe493b24",
            "79e396d5d32b49118e0de71d38dcaccf",
            "f66bc8ee9d0f4600a40882238bbc1354",
            "f7d829d1c6cc491aaa9e830a4ad6f2e3",
            "6424aa7f8e7e438b89224551f13465c8"
          ]
        },
        "outputId": "d85774ca-22e8-4e8b-c46a-7deed029ca71"
      },
      "source": [
        "\n",
        "# Load the pre-trained image captioning model and components\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "image_processor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "# Initialize translation pipeline for English -> Hindi\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-hi\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "max_length = 16\n",
        "num_beams = 1\n",
        "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
        "\n",
        "def predict_step(image):\n",
        "    try:\n",
        "        if image.mode != \"RGB\":\n",
        "            image = image.convert(mode=\"RGB\")\n",
        "\n",
        "        # Pass the image directly as the first argument\n",
        "        pixel_values = image_processor(image, return_tensors=\"pt\").pixel_values\n",
        "        pixel_values = pixel_values.to(device)\n",
        "\n",
        "        print(\"Model before generate:\", model is not None) # Print model status before generate\n",
        "        output_ids = model.generate(pixel_values, **gen_kwargs)\n",
        "\n",
        "        preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "        preds = [pred.strip() for pred in preds]\n",
        "        caption = preds[0]\n",
        "\n",
        "        hindi_caption = translator(caption, max_length=40)[0]['translation_text']\n",
        "\n",
        "        return caption, hindi_caption\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.61k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4fd4f4d63b74d90bd9818244717bff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/982M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15576d1805524c7d994ed3a9754c8b66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/982M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "363d0ff406834ad2872f1a3037413283"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.48.3\"\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'> is overwritten by shared decoder config: GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 50256,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0a58d7603fd45cf8b8617a6b2bf5d27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/241 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b102f1d563bc486e99d3cbaff47a9bd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcdab60d7da144f3b9189a5602c2c01b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "975cd5472573418685a1fec5e91506c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dae6f9f7cc4442bdb96f9e9c95ce4f67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92f14646a51d4a1ca977f98a0db511e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \ud83e\uddea Generating Captions\n",
        "\n",
        "Let\u2019s test the model on some new images and see how well it generates captions. Also testing out the model on how well it generates images out of the captions we provide.\n"
      ],
      "metadata": {
        "id": "cMLSO2XsnXTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_step,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\"text\", \"text\"],\n",
        "    title=\"Image Captioning + Generation\",\n",
        "    description=\"Upload an image to get caption and Hindi translation. Or enter a caption to generate an image.\"\n",
        ")\n",
        "\n",
        "iface2 = gr.Interface(\n",
        "    fn=generate_image_from_caption,\n",
        "    inputs=gr.Textbox(label=\"Enter Caption\"),\n",
        "    outputs=gr.Image(type=\"pil\"),\n",
        "    title=\"Text-to-Image Generator\",\n",
        "    description=\"Enter a caption to generate an image using Stable Diffusion.\"\n",
        ")\n",
        "\n",
        "gr.TabbedInterface([iface, iface2], [\"Image \u2192 Caption\", \"Caption \u2192 Image\"]).launch(debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901,
          "referenced_widgets": [
            "89fd9b26541441d287e00db26ddcbdb1",
            "33206b5e47df4a64ae88dff6dcd788b1",
            "1204da91f8434500907056c96822ab4a",
            "2c63ecc64fb64244982ea2c886b8294c",
            "ee4d31b4e2c9496cb53ae4f5785086b1",
            "e1b5860f3d7c40a49be1a15438d1be91",
            "f426f16381c94e9b8a6c34b438430194",
            "98cefa844d1743e9bad210dfaeeff970",
            "154d2cae8db243a1be749b81b283412c",
            "d60980ff1e634d909b497464d1094881",
            "b01b87da2cf5489e8dfd6879385e8923",
            "0e8455d68e354fff93a715f6de5a69cb",
            "d66a65b9d409465c8fd0c9829a04717c",
            "bc23c01aa5114faaaebe82a5f1ae3aff",
            "8286e3309c4c4feebb2b3423497594ad",
            "f75b879145244927bc7876dd7817a943",
            "347101d92ed6440e87fc6125cec2c7b8",
            "3dff174528f84f51ad9be8c6ad0e6494",
            "ae3b4a6daef4419c81f63036c9355bcd",
            "e0cc62ac1c124d6ca5465fa9e0302de1",
            "3573f650d05e40378c800981871984c6",
            "037dc85da03844e9b0e964e6e6ddd29b",
            "31008d0aaef24bae8952d8dc235e6aaf",
            "25642655c97a48c09280f9bfc4a88ac5",
            "8c905ac179da4b21aa8dd162c0cd7c21",
            "92d83bcf20e0459eaa02b2e03185f384",
            "1e490cc2ffbe48808a64b249904ce0eb",
            "ebd6f4b7ce764e46bf8627f424c9b547",
            "090f3e35cc5e4fcea52c4fbb4a62932f",
            "92cb41d98fcb48e2a70382f584716816",
            "5a3459e4b4454e6487a40733ccec7272",
            "9ffff0abfcb4493b9761e71fbc499364",
            "5cba40fe8b754143878455563edc380e",
            "c7b74b8068b04b9d8ef8cb615971f1a0",
            "6a1ec99b473247cd8ab426ba6f7c2df3",
            "a8312575ce144497a845ea1594a907ac",
            "c12614de3a0944dd98266095bb529210",
            "04ce2944636049c2b0e6b04f9444489f",
            "810eb48097964ae48f2a98a28a695974",
            "452fce14b84f4fd1a9b00ed016b2aa96",
            "fdbb54c89051475aafa600dc0d518007",
            "a1435a4abd4c4909a6703a7b297464d1",
            "c14404c98b624894b7a0e876e582c030",
            "7ca622dc114b4455b754041617302c4a"
          ]
        },
        "id": "Fz05VJqMHkbW",
        "outputId": "a46ec90e-6020-4988-93e9-45a69ee39a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://04c0985dcefde6b692.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://04c0985dcefde6b692.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model before generate: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89fd9b26541441d287e00db26ddcbdb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e8455d68e354fff93a715f6de5a69cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31008d0aaef24bae8952d8dc235e6aaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7b74b8068b04b9d8ef8cb615971f1a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://04c0985dcefde6b692.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \u2705 Wrapping Up\n",
        "\n",
        "This was a simple but solid implementation of image captioning using a CNN + Bidirectional LSTM. There\u2019s a lot of potential to improve this with attention mechanisms or transformers \u2014 but this gives us a strong starting point.\n",
        "\n",
        "Thanks for checking it out! \ud83d\ude80\n"
      ],
      "metadata": {
        "id": "2lNMVxYDnncI"
      }
    }
  ]
}