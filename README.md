# img2cap-cap2img-vit-gpt2
# ğŸ§  Image Captioning & Generation with Bidirectional LSTM

This project demonstrates a **bidirectional deep learning system** that can:

âœ… Generate natural-language captions from input images  
âœ… Generate relevant images from given textual captions  

It combines a **Vision Transformer (ViT)** for feature extraction and a **Bidirectional LSTM** for language understanding/generation.
The result is a dual-capable system that bridges vision and language in both directions. 
A bidirectional vision-language model that generates captions from images and retrieves or generates images from captions, using ViT-GPT2 with Hugging Face Transformers.

**Repository Strucutre**
img2cap-cap2img-vit-gpt2/
â”œâ”€â”€ README.md                          # Project summary and usage
â”œâ”€â”€ data/                              # testing images for the model
â”œâ”€â”€ notebook/                          # Jupyter notebook of the model
â”‚   â””â”€â”€ Fraud_Detection_Personalized_Modeling.ipynb

---


## ğŸš€ Features

- ğŸ“· Caption generation from images using ViT + BiLSTM
- ğŸ–¼ï¸ Image generation from text descriptions (via decoder pipeline)
- ğŸ§  Bidirectional image-text understanding
- ğŸ§ª Gradio interface for interactive input/output
- ğŸŒ Built-in translation pipeline for multilingual captioning

---

## ğŸ§° Tech Stack

- Python
- TensorFlow / PyTorch
- HuggingFace Transformers
- Gradio
- Jupyter Notebook

---
