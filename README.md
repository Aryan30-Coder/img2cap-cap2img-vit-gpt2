# img2cap-cap2img-vit-gpt2
# 🧠 Image Captioning & Generation with Bidirectional LSTM

This project demonstrates a **bidirectional deep learning system** that can:

✅ Generate natural-language captions from input images  
✅ Generate relevant images from given textual captions  

It combines a **Vision Transformer (ViT)** for feature extraction and a **Bidirectional LSTM** for language understanding/generation.
The result is a dual-capable system that bridges vision and language in both directions. 
A bidirectional vision-language model that generates captions from images and retrieves or generates images from captions, using ViT-GPT2 with Hugging Face Transformers.

**Repository Strucutre**
img2cap-cap2img-vit-gpt2/
├── README.md                          # Project summary and usage
├── data/                              # testing images for the model
├── notebook/                          # Jupyter notebook of the model
│   └── Fraud_Detection_Personalized_Modeling.ipynb

---


## 🚀 Features

- 📷 Caption generation from images using ViT + BiLSTM
- 🖼️ Image generation from text descriptions (via decoder pipeline)
- 🧠 Bidirectional image-text understanding
- 🧪 Gradio interface for interactive input/output
- 🌍 Built-in translation pipeline for multilingual captioning

---

## 🧰 Tech Stack

- Python
- TensorFlow / PyTorch
- HuggingFace Transformers
- Gradio
- Jupyter Notebook

---
